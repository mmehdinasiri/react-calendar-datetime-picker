name: Performance Tests

on:
  pull_request:
    branches:
      - main
    types: [opened, synchronize, reopened, ready_for_review]
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  performance:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch full history for proper baseline comparison

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: |
            pnpm-lock.yaml
            ${{ github.event_name == 'pull_request' && 'main-branch/pnpm-lock.yaml' || '' }}

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build library
        run: pnpm run build

      - name: Check bundle size
        run: |
          echo "Checking bundle sizes..."
          node performance/scripts/check-bundle-size.js
        continue-on-error: false

      - name: Run performance tests
        run: |
          echo "Running performance tests on current branch..."
          node performance/scripts/extract-performance-metrics.js
        continue-on-error: false

      - name: Checkout main branch for baseline
        if: github.event_name == 'pull_request'
        uses: actions/checkout@v4
        with:
          ref: ${{ github.base_ref }}
          path: main-branch

      - name: Measure baseline performance
        if: github.event_name == 'pull_request'
        working-directory: main-branch
        continue-on-error: true
        run: |
          echo "Measuring baseline performance on main branch..."

          # Check if performance directory exists
          if [ ! -d "performance" ]; then
            echo "‚ö†Ô∏è Performance directory not found in main branch. Skipping baseline measurement."
            exit 0
          fi

          # Install dependencies for main branch
          pnpm install --frozen-lockfile || {
            echo "‚ö†Ô∏è Failed to install dependencies on main branch. Skipping baseline measurement."
            exit 0
          }

          # Build main branch (may fail if project structure is different)
          pnpm run build || {
            echo "‚ö†Ô∏è Failed to build main branch (likely different project structure). Skipping baseline measurement."
            exit 0
          }

          # Run performance tests on main branch
          node performance/scripts/extract-performance-metrics.js || {
            echo "‚ö†Ô∏è Failed to run performance tests on main branch. Skipping baseline measurement."
            exit 0
          }

          # Copy the metrics to the parent directory with a different name
          if [ -f "performance/results/performance-metrics.json" ]; then
            cp performance/results/performance-metrics.json ../performance/results/performance-metrics-main.json
            echo "‚úÖ Baseline metrics saved successfully"
          else
            echo "‚ö†Ô∏è Performance metrics file not found. Skipping baseline measurement."
            exit 0
          fi

      - name: Generate performance report
        id: performance-report
        run: |
          echo "Generating performance report..."

          # Check if baseline metrics exist and include them in the report
          if [ -f "performance/results/performance-metrics-main.json" ]; then
            echo "Including baseline metrics in report..."
            node performance/scripts/generate-performance-report.js report performance/results/performance-metrics.json performance/results/performance-report.md performance/results/performance-metrics-main.json
          else
            echo "No baseline metrics found, generating report without comparison..."
            node performance/scripts/generate-performance-report.js report performance/results/performance-metrics.json performance/results/performance-report.md
          fi

          # Set output for GitHub Actions
          echo "report<<EOF" >> $GITHUB_OUTPUT
          cat performance/results/performance-report.md >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Generate comparison report
        if: github.event_name == 'pull_request'
        id: comparison-report
        continue-on-error: true
        run: |
          echo "Generating performance comparison report..."

          # Check if baseline metrics exist
          if [ ! -f "performance/results/performance-metrics-main.json" ]; then
            echo "‚ö†Ô∏è Baseline metrics not found. Skipping comparison report."
            echo "comparison<<EOF" >> $GITHUB_OUTPUT
            echo "## ‚ö†Ô∏è Baseline Comparison Unavailable" >> $GITHUB_OUTPUT
            echo "" >> $GITHUB_OUTPUT
            echo "Baseline performance metrics from main branch are not available. This may be because:" >> $GITHUB_OUTPUT
            echo "- The main branch has a different project structure" >> $GITHUB_OUTPUT
            echo "- Performance tests are not set up on the main branch" >> $GITHUB_OUTPUT
            echo "- The baseline measurement step encountered an error" >> $GITHUB_OUTPUT
            echo "" >> $GITHUB_OUTPUT
            echo "Current branch performance metrics are still available in the report above." >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            exit 0
          fi

          node performance/scripts/generate-performance-report.js compare performance/results/performance-metrics-main.json performance/results/performance-metrics.json performance/results/performance-comparison.md

          # Set output for GitHub Actions
          echo "comparison<<EOF" >> $GITHUB_OUTPUT
          cat performance/results/performance-comparison.md >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Check performance regression
        if: github.event_name == 'pull_request'
        continue-on-error: true
        run: |
          echo "Checking for significant performance regressions..."
          node -e "
          const fs = require('fs');

          // Check if baseline file exists
          if (!fs.existsSync('performance/results/performance-metrics-main.json')) {
            console.log('‚ö†Ô∏è Baseline metrics not found. Skipping regression check.');
            console.log('This is expected if the main branch has a different project structure.');
            process.exit(0);
          }

          try {
            const baseline = JSON.parse(fs.readFileSync('performance/results/performance-metrics-main.json', 'utf8'));
            const current = JSON.parse(fs.readFileSync('performance/results/performance-metrics.json', 'utf8'));

            let hasRegression = false;
            const regressions = [];

            Object.entries(current).forEach(([key, val]) => {
              const base = baseline[key];
              if (!base || key.includes('Calls')) return; // Skip missing metrics and call counts

              const percentChange = ((val - base) / base) * 100;
              const absoluteChange = val - base;

              // Skip metrics that are too small to be meaningful (< 1ms)
              if (base < 1 && val < 1) return;

              // Flag regressions that are both significant percentage AND absolute change
              // OR large absolute changes regardless of percentage
              const significantRegression = (
                (percentChange > 15 && absoluteChange > 2) || // 15% + 2ms minimum
                absoluteChange > 5 // OR 5ms absolute change
              );

              if (significantRegression) {
                hasRegression = true;
                regressions.push(\`‚ùå \${key}: \${percentChange.toFixed(1)}% slower (\${base.toFixed(2)}ms ‚Üí \${val.toFixed(2)}ms)\`);
              }
            });

            if (hasRegression) {
              console.log('üö® PERFORMANCE REGRESSIONS DETECTED:');
              regressions.forEach(reg => console.log(\`  \${reg}\`));
              console.log('');
              console.log('These changes exceed the 15% performance regression threshold.');
              console.log('Consider optimizing before merging.');
              process.exit(1);
            } else {
              console.log('‚úÖ No significant performance regressions detected.');
            }
          } catch (error) {
            console.log('‚ö†Ô∏è Could not check for regressions:', error.message);
            console.log('Continuing without regression check...');
            process.exit(0);
          }
          "

      - name: Comment PR with performance results
        if: github.event_name == 'pull_request'
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const report = process.env.REPORT || 'Performance report not available';
            const comparison = process.env.COMPARISON || '## ‚ö†Ô∏è Baseline Comparison Unavailable\n\nBaseline performance metrics from main branch are not available.';

            const fullReport = `${report}\n\n---\n\n${comparison}`;

            // Check if we already commented
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.data.find(comment =>
              comment.body.includes('Performance Benchmark Results') &&
              comment.user.type === 'Bot'
            );

            if (existingComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: fullReport
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: fullReport
              });
            }
        env:
          REPORT: ${{ steps.performance-report.outputs.report }}
          COMPARISON: ${{ steps.comparison-report.outputs.comparison || 'Baseline comparison not available' }}

      - name: Upload performance artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance-results-${{ github.sha }}
          path: |
            performance/results/performance-metrics.json
            performance/results/performance-report.md
            ${{ github.event_name == 'pull_request' && 'performance/results/performance-comparison.md' || '' }}
            ${{ github.event_name == 'pull_request' && 'performance/results/performance-metrics-main.json' || '' }}
