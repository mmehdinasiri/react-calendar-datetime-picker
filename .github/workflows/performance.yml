name: Performance Tests

on:
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened, ready_for_review]
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  performance:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Environment
        uses: ./.github/actions/setup-pnpm-env # Optional: You can keep individual steps if you prefer
        # OR keep these 2 steps here if you don't have a composite action:
      - uses: pnpm/action-setup@v4
        with: { version: 10 }
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'
          cache-dependency-path: |
            pnpm-lock.yaml
            ${{ github.event_name == 'pull_request' && 'main-branch/pnpm-lock.yaml' || '' }}

      - name: Install & Build (Current Branch)
        run: |
          pnpm install --frozen-lockfile
          pnpm run build

      - name: Run Checks (Current Branch)
        run: |
          node performance/scripts/check-bundle-size.js || true
          node performance/scripts/extract-performance-metrics.js

      # --- BASELINE COMPARISON SECTION ---

      - name: Checkout main branch
        if: github.event_name == 'pull_request'
        uses: actions/checkout@v4
        with:
          ref: ${{ github.base_ref }}
          path: main-branch
          fetch-depth: 0

      - name: Measure Baseline (Isolated)
        if: github.event_name == 'pull_request'
        id: measure-baseline
        # We run the script created in Step 1
        run: bash performance/scripts/measure-baseline.sh

      - name: Generate Reports
        id: performance-report
        run: |
          # 1. Main Report
          node performance/scripts/generate-performance-report.js report \
            performance/results/performance-metrics.json \
            performance/results/performance-report.md \
            performance/results/performance-metrics-main.json

          # 2. Comparison (Only if baseline exists)
          if [ -f "performance/results/performance-metrics-main.json" ]; then
            node performance/scripts/generate-performance-report.js compare \
              performance/results/performance-metrics-main.json \
              performance/results/performance-metrics.json \
              performance/results/performance-comparison.md
          fi

          # Output for PR Comment
          echo "report<<EOF" >> $GITHUB_OUTPUT
          cat performance/results/performance-report.md >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          if [ -f "performance/results/performance-comparison.md" ]; then
            echo "comparison<<EOF" >> $GITHUB_OUTPUT
            cat performance/results/performance-comparison.md >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          fi

      - name: Check Regression
        if: github.event_name == 'pull_request'
        # We run the node script created in Step 2
        run: node performance/scripts/check-regression.js

      - name: Comment PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const report = process.env.REPORT || 'Report unavailable';
            const comparison = process.env.COMPARISON || 'Baseline comparison unavailable (Main branch may differ)';
            const body = `${report}\n\n---\n\n${comparison}`;

            const { owner, repo } = context.repo;
            const issue_number = context.issue.number;

            const comments = await github.rest.issues.listComments({ owner, repo, issue_number });
            const botComment = comments.data.find(c => c.body.includes('Performance Benchmark Results') && c.user.type === 'Bot');

            if (botComment) {
              await github.rest.issues.updateComment({ owner, repo, comment_id: botComment.id, body });
            } else {
              await github.rest.issues.createComment({ owner, repo, issue_number, body });
            }
        env:
          REPORT: ${{ steps.performance-report.outputs.report }}
          COMPARISON: ${{ steps.performance-report.outputs.comparison }}

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: performance/results/
